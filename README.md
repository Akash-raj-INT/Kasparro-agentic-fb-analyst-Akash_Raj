# Kasparro â€” Agentic Facebook Performance Analyst

A fully agentic pipeline that analyzes Facebook Ads performance, diagnoses ROAS fluctuations, validates insights, and generates creative recommendations.

This upgraded version includes:
- Structured JSON logging  
- Retry & backoff logic  
- Schema validation & drift detection  
- Observability metrics  
- Clean agent-based architecture  
- Config-driven behavior  
- Production-style orchestration  

---

## ğŸš€ Quick Start

```bash
python -V  # Python >= 3.10 recommended
python -m venv .venv
.\.venv\Scripts\activate   # Windows PowerShell
pip install -r requirements.txt
python -m src.run "Analyze ROAS drop in last 7 days"
```

---

## ğŸ“‚ Data Setup

### Option A â€” Sample Data
Place a sample file here:

```
data/sample_fb_ads.csv
```

### Option B â€” Full Data
Set environment variable:

```bash
setx DATA_CSV "C:\path\to\synthetic_fb_ads_undergarments.csv"
```

Then in `config/config.yaml`:

```yaml
use_sample_data: false
paths:
  data_csv_env: "DATA_CSV"
```

---

## âš™ï¸ Configuration

`config/config.yaml`:

```yaml
python: "3.12"
random_seed: 42

paths:
  sample_csv: "data/sample_fb_ads.csv"
  reports_dir: "reports"
  data_csv_env: "DATA_CSV"

metrics:
  low_ctr_threshold: 0.01
  low_roas_threshold: 1.2
  window_days: 7
```

---

## ğŸ§  Agent Architecture

```
User Query
    â†“
Planner Agent
    â†“
Data Agent
 - Loads CSV (polars)
 - Schema validation (schema/input_schema.json)
 - Drift detection
 - Summaries: by_date, by_campaign, low_ctr
    â†“
Insight Agent
 - Generates hypotheses (ROAS drop, CTR drop, fatigue)
    â†“
Evaluator Agent
 - Validates hypotheses quantitatively
 - Adjusts confidence scores
    â†“
Creative Generator
 - Suggests headlines, message variations, CTAs
    â†“
Pipeline Output
 - report.md
 - insights.json
 - creatives.json
 - metrics.json
 - logs/traces.jsonl
```

---

## ğŸ”§ Detailed Agent Breakdown

### **1. PlannerAgent**
Interprets the user query and creates an ordered execution plan.

### **2. DataAgent**
- Reads CSV using polars  
- Validates schema against `schema/input_schema.json`  
- Logs missing/extra columns  
- Computes:
  - Daily metrics  
  - Campaign-level metrics  
  - Low-CTR ad subset  

### **3. InsightAgent**
Creates hypotheses based on:
- ROAS anomaly detection  
- CTR decline  
- Creative performance changes  
- Audience fatigue  

### **4. EvaluatorAgent**
Validates hypotheses using:
- Spend share analysis  
- Threshold checks (ROAS, CTR)  
- Confidence score adjustments  

### **5. CreativeGeneratorAgent**
Generates:
- New headline ideas  
- Body copy  
- Calls to action  
- Audience-tailored variations  

---

## ğŸ“ Outputs

Files generated under `/reports`:

```
reports/
 â”œâ”€â”€ report.md
 â”œâ”€â”€ insights.json
 â”œâ”€â”€ creatives.json
 â””â”€â”€ metrics.json
```

### **Example: insights.json**
```json
{
  "evaluated_hypotheses": [
    {
      "id": "roas_drop_recent_vs_prev",
      "confidence": 0.78,
      "evidence": {
        "recent_roas": 1.21,
        "previous_roas": 1.87,
        "low_roas_spend_share": 0.46
      }
    }
  ]
}
```

---

## ğŸ“Š Observability & Logging

### **Structured Logging**
All agents log JSON events to:

```
logs/traces.jsonl
```

Fields logged:
- timestamp  
- agent name  
- event name  
- status (start, end, error)  
- duration (if applicable)  
- extra metadata  

### **Metrics**
Pipeline metrics saved to:

```
reports/metrics.json
```

Includes:
- total runtime  
- memory usage  
- rows processed  
- hypotheses generated  
- creatives generated  

---

## ğŸ›¡ Reliability Features

### âœ” Retry & Backoff
All critical operations use a retry decorator:
- 3 retries  
- exponential backoff  
- errors logged per attempt  

### âœ” Schema Validation
Loaded CSV validated via:

```
schema/input_schema.json
```

Detects:
- missing columns  
- extra columns  
- schema drift  

All drift warnings logged.

---

## ğŸ“˜ Repository Structure

```
kasparro-agentic-fb-analyst/
â”œâ”€ README.md
â”œâ”€ requirements.txt
â”œâ”€ config/
â”‚  â””â”€ config.yaml
â”œâ”€ schema/
â”‚  â””â”€ input_schema.json
â”œâ”€ src/
â”‚  â”œâ”€ run.py
â”‚  â”œâ”€ agents/
â”‚  â”‚  â”œâ”€ planner.py
â”‚  â”‚  â”œâ”€ data_agent.py
â”‚  â”‚  â”œâ”€ insight_agent.py
â”‚  â”‚  â”œâ”€ evaluator.py
â”‚  â”‚  â””â”€ creative_generator.py
â”‚  â”œâ”€ orchestrator/
â”‚  â”‚  â””â”€ pipeline.py
â”‚  â””â”€ utils/
â”‚     â”œâ”€ logger.py
â”‚     â”œâ”€ retry.py
â”‚     â””â”€ schema_utils.py
â”œâ”€ logs/
â”‚  â””â”€ traces.jsonl
â”œâ”€ reports/
â”‚  â”œâ”€ report.md
â”‚  â”œâ”€ insights.json
â”‚  â”œâ”€ creatives.json
â”‚  â””â”€ metrics.json
â””â”€ data/
   â””â”€ sample_fb_ads.csv
```

---

## ğŸ§ª Tests

```
tests/test_evaluator.py
tests/test_schema_validation.py
```

---

## ğŸ¯ Release

Create release tag:

```bash
git tag v1.0
git push origin v1.0
```

---

## ğŸ“ Self-Review (for PR)

- Explain design choices  
- Why agent separation?  
- Why structured logging?  
- Why schema validation?  
- Which metrics were chosen and why?  

---

## âœ” Ready for Submission

This README meets the companyâ€™s P0, P1, and P2 requirements.

